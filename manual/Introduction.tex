\documentclass[12pt]{article}
\usepackage{xeCJK}%preamble part
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage[a4paper, inner=1.5cm, outer=3cm, top=2cm, bottom=3cm, bindingoffset=1cm]{geometry}
\usepackage{epstopdf}
\usepackage{array}
\usepackage{fontspec}
\usepackage{gensymb}
\usepackage[citecolor=blue]{hyperref}
\usepackage{amsmath}
\usepackage{makecell}
\usepackage[lofdepth,lotdepth]{subfig}
\setCJKmainfont[BoldFont={SimHei}]{SimSun}
\setCJKmonofont{SimSun}
\setmainfont{Times New Roman}
\newCJKfontfamily[hei]\heiti{SimHei}
\setlength{\extrarowheight}{4pt}
\setlength{\parindent}{1cm}
\begin{document}
\title{\textbf{\fontsize{15.75pt}{\baselineskip}{用户型德语初学者词典Klick Auf Deutsch Hilfer设计理念}}}
\author{\fontsize{12pt}{\baselineskip}{计41 牛行知 数33 赵丰}}

\maketitle
\renewcommand{\abstractname}{摘要}
\renewcommand*\contentsname{目录}
\begin{abstract}
在国内外语学习的热潮下双语词典的编纂一直是为人们所忽视的主题，传统词典一直由少数专家把关，编一部词典的周期长，门槛高；现代信息技术的进步为使用计算机网络技术进行协作式编辑，充分考虑用户需求，缩短编辑周期和提高实用性方面提供了可能。本次项目试图以用户型德语初学者词典为突破口探索这种可能性。目前已经实现了词典的浏览和在线编辑模块。
\end{abstract}
\tableofcontents
\large
\twocolumn
\setlength{\columnseprule}{1pt}

\section[问题背景]{问题背景：我国双语学习型词典的设计缺位}
尽管英汉词典学是我国外语人才培养的一个二级学科，但我国真正流行的词典几乎都是所引进或合作编纂出版的外来词典，其编纂设计者与使用者形成了主客二分的疏离关系，设计者对于需求的认知主要源于编者主体的专业知识判断，而非对实际用户需求调研的结果。\cite{Bib1}

我国原创英汉汉英类词典，在国内词典市场的份额缺失严重，这和脱离用户需求，盲目照翻单语词典不无关系。

从表面上看，我国电子词典呈现出一片繁荣景象，所涉语言从英汉延伸至其他小语种，但实际情况是电子产品公司与计算机软件开发公司对电子词典表现出极大的热情，辞书出版机构将纸制词典的电子版权转让给电子出版商，而后者只是简单地把印在纸上的东西搬进芯片。

欧美电子词典以辞书为本体来开发电子词典，注重词典数据库的建设，而我国内地则是以电子为本体，先是由IT公司开发，出现问题后又转向引进权威词典。\cite{Bib2}

\section{设计目标描述}
	电子词典的核心功能是单词查询的浏览功能。
	电子词典的界面设计一方面要继承纸制词典的风格，另一方面在不同的媒介下有一定的发挥空间。
	
	为实现上述设计目标，我们以网页为平台开发了Klick Auf Deutsch Hilfer。
	在开发过程中，为了提高编辑工作效率，我们设计了用户编辑模块。
\section{单词查询}

\subsection{\textbf{\fontsize{12pt}{\baselineskip}{数据视角}}}
	我们设计词典抛弃了一般电子词典采用的急键值加表项的方式，而采用超文本标记语言xml组织每一个词项。单独的xml文件以词条的编号命名，如1.xml表示名词类中的第一个,词项是Abend;V100.xml表示动词类中的第100个，词项是wissen.
	
	xml可以自定义元素和属性，为此我们采用了文档类型定义dtd的方法，考虑到不同词性的词有不同的属性，每一个词性我们单独定义了一个dtd文件，在xml文档的头部，显示指明了它被哪一个dtd所约束，如NounModel.dtd。虽然不同词性的词有不同的dtd,但其大致结构相同。具体说来，每一个合法的xml首先都要有一个根元素名为Entry.Entry下必须依次出现元素Stichwort，Einheit/Anteil,zusammengesetzteWörter,
Synonymegruppe,Antonymegruppe,
Kollokationen,AllgemeineErläuterungen.

这里有的子元素结构比较简单，比如Stichwort下只包含了词形的信息。
Einheit/Anteil元素是适配考虑到清华大学德语教学正在使用的教材为每个单词提供的其所在单元和所在单元具体模块的信息。
zusammengesetzteWörter元素提供德语中的和该词有关的复合词的信息，
由于德语中复合词数量更多，相应的我们在zusammengesetzteWörter
下设了KompositaCollection和abgeleiteteWörter两个子元素，
分别包含合成词类和派生词类。在合成词类下，为支持后期多种检索方式，我们将其主要分为K\_和 \_K型,分别表示这个词项在该合成词的位置
是在前面还是后面，派生词类下对每个由该词项派生的词必须注明它的词性，否则按照dtd的语法检查规则，整篇文档就是不合法的。

对于Entry下接下来的三个元素，分别表示同义词集合、反义词集合和词组集合，其中我们在编辑的过程中发现，同反义词集合具有稀疏性。

整个词条中最重要的部分是AllgemeineErläuterungen，其结构也最复杂。考虑到一词多义的可能性，该“一般性释义”下设若干个Eintrag,
至少要有一个Eintrag.每一个Eintrag有Chinesisch和BeispielSammlung
两个子元素，分别是汉语释义和例句集，每一个例句集是由若干个
Beispiel组成的，而每一个Beipiel由Satz和Übersetzung组成。该部分对
整个文档树的深度贡献最大。

同时，我们考虑到单词之间错综复杂的语义关系，在Eintrag的相关子元素下设置了link属性，其值为相对应单词的文件名称，如essen词项下<\_K link=''1.xml''>Abendessen<\/K>就表示Abendessen可以链接到Abend.这种方法不仅为展示数据提供了统一个接口，还为用网络的方法做关联分析提供了数据基础。
\subsection{\textbf{\fontsize{12pt}{\baselineskip}{界面视角}}}
\section{用户编辑}

\section{背单词}
我们打算基于已有的词典内容开发背单词的模块，传统的背单词往往基于简单的随机因子和分数累加，在开发之前，我们仔细学习了Item Response
Theory,并以此理论为基础，建立单词测试的数学模型，用统计学中分析数据的方法，在数据库和CS架构的技术基础上尝试实现背单词模块，目前该
模块正在开发过程中。
\subsection{\textbf{\fontsize{12pt}{\baselineskip}{词汇量统计方法}}}
\cite{Bib4}中给出了估计正常人遇到的词汇量的基本方法，首先统计出Alphabetical Type（N)与语料库规模(M)的关系，Herdan's Law指出N是M的幂函数且幂指数小于1，其次通过抽样调查的方法统计某一特定人群在一段时间内exposed to 语言输入的tokens，对这些tokens进行统计去重再外推即得到encountered AT值。
传统的词汇测量方法是基于Classical Test Theory对于每个test item,一般结果是二值的，即只有对和错两个result，累加后的结果可以作为observed score。CTT认为X=T+E,T是true score,E是error.
CTT还有三个基本假设：
\begin{enumerate}
\item{E的期望为0}
\item{T和E不相关}
\item{不同次测量结果(对不同participants)相互独立}
\end{enumerate}
该测量的性能评估用reliability表示，其数学定义为
\begin{equation}
\rho_{XT}^2=\frac{\sigma_T^2}{\sigma_X^2}
\end{equation}
在心理学领域，要测量某个latent variable,不能采用独立重复试验的方法，如果要基于单次测量估计$\rho_{XT}$，该单次测量应该在subscale上应该由同样能反应出被测量laten variable 水平的item组成。
基于不同participants,可以得到item 矩阵，分析该item矩阵可估计$\rho_{XT}$。该方法的数学模型如下：
假设一test有k个items $u_j,j=1,..,k$,对第i个participant其总得分为：
\begin{equation}
X_i=\sum_{j=1}^k U_{ij}
\end{equation}
上式中$U_{ij}$表示对第i个参与者在第j个item上observed score。
可以证明，Cronbach's alpha是$\rho_{XT}$的下界。
\begin{equation}
\alpha=\frac{k}{k-1}(1-\frac{\sum_{i=1}^k \sigma_{U_j}^2}{\sigma_X^2})
\end{equation}
$\alpha$介于0,1之间，用于评估Test性能，一般认为$\alpha$值在0.9以上会有redundacy of items,但对于individual high-stakes testing这又是必要的。
在CTT框架下,$\alpha$只能用于评估Test总体性能，如果要做item analysis,对于每个item,计算p value(表征item difficulty)和item-total correlation(表征 discrimination).
CTT的问题在于评估Test性能和被试者特征(examinee characteristics)有关,而且对于不同被试者假定true score均值不同方差相等。
在psychometrics,一般不使用CTT而用IRT方法(item response theory).这是一种基于item而不是test(由许多item组成）的方法，IRT要估计latent variable $\theta$,
假设各个item彼此独立，被试者对某个item的回答正确的概率用IRF(item response function)建模.一般$\theta$会做一个归一化,使得其均值为0标准差为1，这样$\hat{\theta}$作为$\theta$的估计值一般在-3到3之前，非常接近0表示水平中等。这种归一化给不同测试集之间相互比较提供了方便。
IRF函数有多种不同的建模方式，一般常用的有Logistic model:
\begin{equation}
p_i(\theta)=c_i+\frac{1-c_i}{1+exp(-a_i(\theta-b_i))}
\end{equation}
上式中i表示被试者的编号，a,b,c是item的参数，分别表征discrimination,difficulty和pseudo guessing,可以从下图(ICC曲线,item characteristic curve)形象地说明这三个参数
\begin{figure}
\caption{三个参数的IRF}
\includegraphics[width=\linewidth]{3PL_IRF.png}
\end{figure}
由上图可以看出$\theta=-3$时被试者仍有概率c答对，对4选1的multiple choice,c=$\frac{1}{4}$,b是$p(\theta)=\frac{c+1}{2}$的点,即最大值1和最小值c的平均值的点，同时也是LRF曲线最陡的点，可以衡量difficulty.a和p'(b)成正比，a越大曲线两级分化越严重，即ability $\theta$小于某一个阈值答对的正确率为c,大于此阈值答对的正确率为1.
此外LRF曲线还可以从标准正态分布的cdf建模。
三个参数的IRF虽然精确，但实际中估计参数比较繁琐，一般常用的是1个参数(b)的Rasch Model,其可以简化表述为第k个person在第i个item上答对的概率为
\begin{equation}\label{eq:Rasch}
P(X_{ki}=1)=\frac{exp(\beta_k-\delta_i)}{1+exp(\beta_k-\delta_i)}
\end{equation}
上式中$\beta_k$表示ability,$\delta_i$表示difficulty.
在获得person $\times$ item的二维表格数据后，要先根据数据估计Rasch Model 的参数$\vec{\delta}=(\delta_1,..\delta_I)$,常用的方法有极大似然法，CML,EM等，关于这三种方法在Rasch Model参数估计的具体讨论，见\ref{A1}。
\subsection{\textbf{\fontsize{12pt}{\baselineskip}{具体实施步骤}}}
下面的列表给出了我们基于Rasch Model关于CAT(computer adapated testing)背单词的实施方案:
\begin{enumerate}
\item{根据课本内容统计词频，归一化后作为每个单词难度的近似替代量}
\item{每一个用户初始化背单词能力为0，每一次背单词后保留其该次背单词能力的估计值，在下一次背单词时采用之前能力值的加权平均值，对于该平均值-单词难度>3的单词则不予考虑，在其他单词中按单词难度进行重要度抽样，样本数量为N个,作为该次背单词的测试集。每次用户的有效测试（没有中途退出和缺失值）保存到服务器的数据库用来更新单词难度。}
\item{定期更新单词难度之前集齐一定数量的测试结果,应考虑到用户的能力变化曲线，有选择地剔除某一部分数据再用CML全局计算单词难度，将计算值与原有的频率值做平均。}
\end{enumerate}
\appendix
\section{First Appendix}\label{A1}
\subsection{JML}
首先讨论JML(joint maximum likelihood)的方法,observed data matrix联合概率似然函数为
\begin{equation}
\begin{split}
\log(\Lambda)=\sum_{k=1}^N \beta_k r_k -\sum_{i=1}^I \delta_i s_i+ \\
\sum_{k=1}^N \sum_{i=1}^I \log(1+exp(\beta_k-\delta_i))
\end{split}
\end{equation}
其中$r_k=\displaystyle\sum_{i=1}^I x_{ki}$,表示第k个person的总分，
$s_i=\displaystyle\sum_{k=1}^N x_{ki}$,表示第i个item的总分。
对对数似然函数关于$\delta_i$和$\beta_k$求偏导，得到含$\beta_k$和
$\delta_i$的非线性方程组为
\begin{eqnarray}\label{eq:JML}
s_i=\sum_{k=1}^N p_{ki},i=1,..I\\
r_k=\sum_{i1}^I p_{ki},k=1,..N
\end{eqnarray}•
上式中$p_{ki}$即为(\ref{eq:Rasch})
\subsection{CML}
对实际应用来说，一般N很大，直接求解(\ref{eq:JML})计算量太大。
故一般先求只含item的边缘概率分布，在item的参数$\delta_i$求出的情况下，由于各个person之间相互独立，只需分别对只含一维参数$\beta_k$的函数求极大值点即可。
对第k个person,其各item得分的joint distribution为
\begin{equation}
\begin{split}
P(\vec{x_k}|\beta_k,\vec{\delta})=\prod_{i=1}^I \frac{exp(x_{ki}(\beta_k-\delta_i))}{1+exp(\beta_k-\delta_i)}\\
=\frac{exp(r_k\beta_k)exp(-\sum_{i=1}^I x_{ki}\delta_i)}{\prod_{i=1}^I (1+exp(\beta_k-\delta_i))}
\end{split}
\end{equation}
由$\vec{x_k}$的联合分布可以求出$r_k$的分布为
\begin{equation}
\begin{split}
P(r_k|\beta_k,\vec{\delta})=\sum_{||\vec{y}||_1=r_k}P(\vec{y}|\beta_k,\vec{\delta})\\
=\frac{exp(r_k\beta_k)\displaystyle\sum_{||\vec{y}||_1=r_k}exp(-\sum_{i=1}^I y_{i}\delta_i)}{\prod_{i=1}^I (1+exp(\beta_k-\delta_i))}
\end{split}
\end{equation}
定义$\gamma_{r|\vec{\delta}}=\displaystyle\sum_{||\vec{y}||_1=r}exp(-\sum_{i=1}^I y_{i}\delta_i)$,为elementary symmetric function,则条件似然函数$P(x_k|r_k,\vec{\delta})$为
\begin{equation}
\begin{split}
P(x_k|r_k,\vec{\delta})=\frac{P(x_k|\beta_k,\vec{\delta})}{P(r_k|\beta_k,\vec{\delta})}\\
=\frac{exp(-x_{ki}\delta_i)}{\gamma_{r_k|\vec{\delta}}}
\end{split}
\end{equation}
上式不含$\beta_k$，说明$r_k$是参数$\beta_k$的充分统计量。
由于各person得分相互独立,只需把N个对数似然函数相加即可。
\begin{equation}
\log(\Lambda(\vec{x}|\vec{r},\vec{\delta}))=\sum_{k=1}^N \frac{exp(-x_{ki}\delta_i)}{\gamma_{r_k|\vec{\delta}}}
\end{equation}
\begin{thebibliography}{}
\bibitem{Bib1}双语学习型词典设计特征研究 外研社2013年出版

\bibitem{Bib2} 计算词典学 上海辞书出版社2011年版

\bibitem{Bib3} \url{https://github.com/Leidenschaft/Deutsch-Lernen}
\bibitem{Bib4} How Many Words Do We Know? Practical Estimates Of
Vocabulary Size Depedenent on Word Definition, the Degree of Language Input and the Participant's Age		frontiers in Psychology
\end{thebibliography}
\end{document}